import random
import os
import cv2
import numpy as np
import tensorflow as tf
import Misc.ImageUtils as iu
import Misc.warpICSTN2 as warp2
import Misc.MiscUtils as mu


class BatchGeneration():
    def __init__(self, sess, WarpI1PatchIdealGen, IOrgPH, HPH):
        self.sess = sess
        self.WarpI1PatchIdealGen = WarpI1PatchIdealGen
        self.IOrgPH = IOrgPH
        self.HPH = HPH
        
    def RandSimilarityPerturbationTF(self, IOrgBatch, HObj, PatchSize, MiniBatchSize, ImageSize=None, Vis=False):
        if(ImageSize is None):
            ImageSize = np.array(np.shape(IOrgBatch))[1:]
            # TODO: Extract MiniBatchSize here

        H, Params = HObj.GetRandReducedHICSTN(TransformType = 'psuedosimilarity', MiniBatchSize = MiniBatchSize)
        opt = warp2.Options(PatchSize=ImageSize, MiniBatchSize=MiniBatchSize, warpType= ['pseudosimilarity'])

        ITensor = tf.convert_to_tensor(np.float32(IOrgBatch), dtype='float')
        HTensor = tf.convert_to_tensor(np.float32(H), dtype='float')
        # Maybe this is the best way? https://dominikschmidt.xyz/tensorflow-data-pipeline/
        for count in range(10):
            Timer1 = mu.tic()
            FeedDict = {self.IOrgPH: IOrgBatch, self.HPH: H}
            WarpI1IdealRet = self.WarpI1PatchIdealGen.eval(feed_dict=FeedDict)# self.sess.run([self.WarpI1PatchIdealGen], feed_dict=FeedDict)
            print(mu.toc(Timer1))

        print('qqqqqqqqqqqqq')

        Timer1 = mu.tic()
        ITensor = tf.convert_to_tensor(np.float32(IOrgBatch), dtype='float')
        HTensor = tf.convert_to_tensor(np.float32(H), dtype='float')
        print(mu.toc(Timer1))
        WarpI1PatchIdealGen = warp2.transformImage(opt, ITensor, HTensor)

        for count in range(10):
            Timer1 = mu.tic()
            WarpI1PatchIdealGen.eval()
            print(mu.toc(Timer1))

        print('qqqqqqqqqqqqqqqq')
        IOrgPH = tf.placeholder(tf.float32, shape=(MiniBatchSize, 300, 300, 3), name='IOrg') 
        HPH = tf.placeholder(tf.float32, shape=(MiniBatchSize, 3, 3), name='LabelH')
        WarpI1PatchIdealGen = warp2.transformImage(opt, IOrgPH, HPH)
        for count in range(10):
            Timer1 = mu.tic()
            FeedDict = {IOrgPH: IOrgBatch, HPH: H}
            WarpI1PatchIdealGen.eval(feed_dict=FeedDict)
            print(mu.toc(Timer1))

        # input('q')

        # # Crop in center for PatchSize
        # P1 = iu.CenterCrop(I1, PatchSize)
        # P2 = iu.CenterCrop(I2, PatchSize)

        # if(Vis is True):
        #     cv2.imshow('I1, I2', np.hstack((I1, I2)))
        #     cv2.imshow('I1, I2', np.hstack((P1, P2)))
        #     cv2.waitKey(0)

        # P1 is I1 cropped to patch Size
        # P2 is I1 Crop Warped (I2 Crop)
        # H is Homography
        # Params is the stuff H is made from 
        return None # I1, I2, P1, P2, H, Params


    def GenerateBatchTF(self, TrainNames, PatchSize, MiniBatchSize, HObj, BasePath, OriginalImageSize):
        """
        Inputs: 
        DirNames - Full path to all image files without extension
        NOTE that Train can be replaced by Val/Test for generating batch corresponding to validation (held-out testing in this case)/testing
        TrainLabels - Labels corresponding to Train
        NOTE that TrainLabels can be replaced by Val/TestLabels for generating batch corresponding to validation (held-out testing in this case)/testing
        ImageSize - Size of the Image
        MiniBatchSize is the size of the MiniBatch
        Outputs:
        I1Batch - Batch of I1 images after standardization and cropping/resizing to ImageSize
        HomeVecBatch - Batch of Homing Vector labels
        """
        IBatch = [] # P1, P2
        I1Batch = []
        I2Batch = []
        HBatch = []
        ParamsBatch = []
        IOrgBatch = [] 

        ImageNum = 0
        while ImageNum < MiniBatchSize:
            # Generate random image
            RandIdx = random.randint(0, len(TrainNames)-1)
            RandImageName = BasePath + os.sep + TrainNames[RandIdx] 
            I = cv2.imread(RandImageName)
            I = iu.RandomCrop(I, OriginalImageSize)
            if (I is None):
                continue
            ImageNum += 1
            IOrgBatch.append(I)

        # Similarity and Patch generation 
        # I1, I2, P1, P2, H, Params = RandSimilarityPerturbationTF(IOrgBatch, HObj, PatchSize, MiniBatchSize, sess, ImageSize = None, Vis = False)
        # for count in range(10):
        self.RandSimilarityPerturbationTF(IOrgBatch, HObj, PatchSize, MiniBatchSize, ImageSize = None, Vis = False)

        input('ww')
        ICombined = np.dstack((P1[:,:,0:3], P2[:,:,0:3]))
        # Normalize Dataset
        # https://stackoverflow.com/questions/42275815/should-i-substract-imagenet-pretrained-inception-v3-model-mean-value-at-inceptio
        IS = iu.StandardizeInputs(np.float32(ICombined))

        # # Append All Images and Mask
        # IBatch.append(IS)
        # I1Batch.append(P1)
        # I2Batch.append(P2)
        # HBatch.append(H)
        # ParamsBatch.append(Params)

        # CompositionsBatch = np.squeeze(CompositionsBatch)
        return IBatch, I1Batch, I2Batch, HBatch, ParamsBatch

